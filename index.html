<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Leo  Feng</title>
    <meta name="author" content="Leo  Feng">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/deer.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://lfeng99.github.io/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="https://scholar.google.com/citations?user=WsRunnEAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://www.semanticscholar.org/author/31787052" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a>
            <a href="https://www.linkedin.com/in/leo-feng" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/lylbfeng" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a>
            
            <!-- <a href="/assets/pdf/" target="_blank" rel="noopener noreferrer" class="float-right">CV</a> -->
          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">About me<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <!-- <span class="font-weight-bold">Leo</span>  Feng -->
           Leo  Feng
          </h1>
          <p class="desc"></p>
        </header>

        <article>


          
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <p>Hi! I’m a PhD student at <a href="https://mila.quebec/" rel="external nofollow noopener" target="_blank">Montreal Institute for Learning Algorithms</a> and Université de Montréal supervised by <a href="https://mila.quebec/en/person/bengio-yoshua/" rel="external nofollow noopener" target="_blank">Prof. Yoshua Bengio</a>. Currently, I am doing a Research Internship at <a href="https://www.borealisai.com/" rel="external nofollow noopener" target="_blank">Borealis AI</a>. My current research interests include Meta-Learning and the design of efficient models.</p>

<p>Previously, I did my Bachelors in Computer Science at University of Oxford (<a href="https://whirl.cs.ox.ac.uk/" rel="external nofollow noopener" target="_blank">WhiRL</a>), working with <a href="https://www.cs.ox.ac.uk/people/shimon.whiteson/" rel="external nofollow noopener" target="_blank">Prof. Shimon Whiteson</a> and <a href="https://luisazintgraf.com/" rel="external nofollow noopener" target="_blank">Dr. Luisa Zintgraf</a> on Meta-Learning and Reinforcement Learning. 
<!-- During this time, I did research internships at University of Kyoto working with [Prof. Atsuko Sehara-Fujisawa](https://zfin.org/ZDB-LAB-160803-1) and at [Brave Software](https://brave.com/).  --></p>

<!-- 
News
-----
* Jan. 2023: Our work [Latent Bottlenecked Attentive Classification](https://arxiv.org/abs/2211.08458) is accepted to ICLR 2023
* Jan. 2023: Our work [Towards Better Selective Classification](https://arxiv.org/abs/2206.09034?context=cs) is accepted to ICLR 2023
* Jan. 2022: Our work [Continuous-Time Meta-Learning with Forward Mode Differentiation
](https://arxiv.org/abs/2203.01443) is accepted to ICLR 2022 as a spotlight paper
* Dec. 2021: Our work [VariBAD: Variational Bayes-Adaptive Deep RL via Meta-Learning](https://jmlr.org/papers/v22/21-0657.html) is accepted to JMLR 
* May. 2021: Our work [Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning](https://icml.cc/virtual/2021/spotlight/10380) is accepted to ICML 2021 -->

            <!-- Social -->
              <div class="social">
                <div class="contact-icons">
                  <a href="https://scholar.google.com/citations?user=WsRunnEAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://www.semanticscholar.org/author/31787052" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a>
            <a href="https://www.linkedin.com/in/leo-feng" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/lylbfeng" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a>
            
            <!-- <a href="/assets/pdf/" target="_blank" rel="noopener noreferrer" class="float-right">CV</a> -->
                </div>

                <div class="contact-note">
                  
                </div>

              </div>
          </div>


          <!-- News -->
          

          <!-- Latest posts -->
          

          <!-- Selected papers -->
          <h2><a href="/publications/" style="color: inherit;">Selected Publications</a></h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#E98A15"><a href="">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="feng2023tree" class="col-sm-8">
        <!-- Title -->
        <div class="title">Tree Cross Attention</div>
        <!-- Author -->
        <div class="author">
        

        <em>Leo Feng</em>, <a href="https://scholar.google.ca/citations?user=T4EeZ9gAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Frederick Tung</a>, <a href="https://hossein-h.github.io/" rel="external nofollow noopener" target="_blank">Hossein Hajimirsadeghi</a>, <a href="https://yoshuabengio.org/" rel="external nofollow noopener" target="_blank">Yoshua Bengio</a>, and <a href="https://scholar.google.ca/citations?user=jyVyVj4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Mohamed Osama Ahmed</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Learning Representations</em>, 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2309.17388" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://openreview.net/forum?id=Vw24wtSddM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Cross Attention is a popular method for retrieving information from a set of context tokens for making predictions. At inference time, for each prediction, Cross Attention scans the full set of tokens. In practice, however, often only a small subset of tokens are required for good performance. Methods such as Perceiver IO are cheap at inference as they distill the information to a smaller-sized set of latent tokens L &lt; N on which cross attention is then applied, resulting in only O(L) complexity. However, in practice, as the number of input tokens and the amount of information to distill increases, the number of latent tokens needed also increases significantly. In this work, we propose Tree Cross Attention (TCA) - a module based on Cross Attention that only retrieves information from a logarithmic O(\log(N)) number of tokens for performing inference. TCA organizes the data in a tree structure and performs a tree search at inference time to retrieve the relevant tokens for prediction. Leveraging TCA, we introduce ReTreever, a flexible architecture for token-efficient inference. We show empirically that Tree Cross Attention (TCA) performs comparable to Cross Attention across various classification and uncertainty regression tasks while being significantly more token-efficient. Furthermore, we compare ReTreever against Perceiver IO, showing significant gains while using the same number of tokens for inference.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#E98A15"><a href="">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="feng2022latent" class="col-sm-8">
        <!-- Title -->
        <div class="title">Latent Bottlenecked Attentive Neural Processes</div>
        <!-- Author -->
        <div class="author">
        

        <em>Leo Feng</em>, <a href="https://hossein-h.github.io/" rel="external nofollow noopener" target="_blank">Hossein Hajimirsadeghi</a>, <a href="https://yoshuabengio.org/" rel="external nofollow noopener" target="_blank">Yoshua Bengio</a>, and <a href="https://scholar.google.ca/citations?user=jyVyVj4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Mohamed Osama Ahmed</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Learning Representations</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2211.08458" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://openreview.net/forum?id=yIxtevizEA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/BorealisAI/latent-bottlenecked-anp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Neural Processes (NPs) are popular methods in meta-learning that can estimate predictive uncertainty on target datapoints by conditioning on a context dataset. Previous state-of-the-art method Transformer Neural Processes (TNPs) achieve strong performance but require quadratic computation with respect to the number of context datapoints, significantly limiting its scalability. Conversely, existing sub-quadratic NP variants perform significantly worse than that of TNPs. Tackling this issue, we propose Latent Bottlenecked Attentive Neural Processes (LBANPs), a new computationally efficient sub-quadratic NP variant, that has a querying computational complexity independent of the number of context datapoints. The model encodes the context dataset into a constant number of latent vectors on which self-attention is performed. When making predictions, the model retrieves higher-order information from the context dataset via multiple cross-attention mechanisms on the latent vectors. We empirically show that LBANPs achieve results competitive with the state-of-the-art on meta-regression, image completion, and contextual multi-armed bandits. We demonstrate that LBANPs can trade-off the computational cost and performance according to the number of latent vectors. Finally, we show LBANPs can scale beyond existing attention-based NP variants to larger dataset settings.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#E98A15"><a href="">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="fengtowards" class="col-sm-8">
        <!-- Title -->
        <div class="title">Towards Better Selective Classification</div>
        <!-- Author -->
        <div class="author">
        

        <em>Leo Feng</em>, <a href="https://scholar.google.ca/citations?user=jyVyVj4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Mohamed Osama Ahmed</a>, <a href="https://hossein-h.github.io/" rel="external nofollow noopener" target="_blank">Hossein Hajimirsadeghi</a>, and <a href="https://amir-abdi.com/" rel="external nofollow noopener" target="_blank">Amir H Abdi</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Learning Representations</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2206.09034" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://openreview.net/forum?id=5gDz_yTcst" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/BorealisAI/towards-better-sel-cls" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We tackle the problem of Selective Classification where the objective is to achieve the best performance on a predetermined ratio (coverage) of the dataset. Recent state-of-the-art selective methods come with architectural changes either via introducing a separate selection head or an extra abstention logit. In this paper, we challenge the aforementioned methods. The results suggest that the superior performance of state-of-the-art methods is owed to training a more generalizable classifier rather than their proposed selection mechanisms. We argue that the best performing selection mechanism should instead be rooted in the classifier itself. Our proposed selection strategy uses the classification scores and achieves better results by a significant margin, consistently, across all coverages and all datasets, without any added compute cost. Furthermore, inspired by semi-supervised learning, we propose an entropy-based regularizer that improves the performance of selective classification methods. Our proposed selection mechanism with the proposed entropy-based regularizer achieves new state-of-the-art results.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#E98A15"><a href="">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="deleucontinuous" class="col-sm-8">
        <!-- Title -->
        <div class="title">Continuous-Time Meta-Learning with Forward Mode Differentiation</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://tristandeleu.github.io/" rel="external nofollow noopener" target="_blank">Tristan Deleu</a>, <a href="https://scholar.google.ca/citations?user=HUmLDxcAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">David Kanaa</a>, <em>Leo Feng</em>, <a href="https://www.giancarlokerg.com/" rel="external nofollow noopener" target="_blank">Giancarlo Kerg</a>, <a href="https://yoshuabengio.org/" rel="external nofollow noopener" target="_blank">Yoshua Bengio</a>, <a href="https://www.guillaumelajoie.com/" rel="external nofollow noopener" target="_blank">Guillaume Lajoie</a>, and <a href="https://pierrelucbacon.com/" rel="external nofollow noopener" target="_blank">Pierre-Luc Bacon</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Learning Representations</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2203.01443" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://openreview.net/forum?id=57PipS27Km" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/tristandeleu/jax-comln" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Drawing inspiration from gradient-based meta-learning methods with infinitely small gradient steps, we introduce Continuous-Time Meta-Learning (COMLN), a meta-learning algorithm where adaptation follows the dynamics of a gradient vector field. Specifically, representations of the inputs are meta-learned such that a task-specific linear classifier is obtained as a solution of an ordinary differential equation (ODE). Treating the learning process as an ODE offers the notable advantage that the length of the trajectory is now continuous, as opposed to a fixed and discrete number of gradient steps. As a consequence, we can optimize the amount of adaptation necessary to solve a new task using stochastic gradient descent, in addition to learning the initial conditions as is standard practice in gradient-based meta-learning. Importantly, in order to compute the exact meta-gradients required for the outer-loop updates, we  devise an efficient algorithm based on forward mode differentiation, whose memory requirements do not scale with the length of the learning trajectory, thus allowing longer adaptation in constant memory. We provide analytical guarantees for the stability of COMLN, we show empirically its efficiency in terms of runtime and memory usage, and we illustrate its effectiveness on a range of few-shot image classification problems.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#e91546"><a href="">JMLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="zintgraf2021varibad" class="col-sm-8">
        <!-- Title -->
        <div class="title">VariBAD: variational Bayes-adaptive deep RL via meta-learning</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://luisazintgraf.com/" rel="external nofollow noopener" target="_blank">Luisa Zintgraf</a>, <a href="https://www.robots.ox.ac.uk/~sschulze/" rel="external nofollow noopener" target="_blank">Sebastian Schulze</a>, <a href="https://www.conglu.co.uk/" rel="external nofollow noopener" target="_blank">Cong Lu</a>, <em>Leo Feng</em>, <a href="https://scholar.google.com/citations?user=rFcdDJEAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Maximilian Igl</a>, <a href="https://scholar.google.com.sg/citations?user=FNiMmWoAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Kyriacos Shiarlis</a>, <a href="https://scholar.google.com/citations?user=SIayDoQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Yarin Gal</a>, <a href="https://scholar.google.com/citations?user=bHsjbLwAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Katja Hofmann</a>, and <a href="https://scholar.google.com/citations?user=9zeEI-cAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Shimon Whiteson</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>The Journal of Machine Learning Research</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://jmlr.org/papers/v22/21-0657.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Trading off exploration and exploitation in an unknown environment is key to maximising expected online return during learning. A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but also on the agent’s uncertainty about the environment. Computing a Bayes-optimal policy is however intractable for all but the smallest tasks. In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn approximately Bayes-optimal policies for complex tasks. VariBAD simultaneously meta-learns a variational auto-encoder to perform approximate inference, and a policy that incorporates task uncertainty directly during action selection by conditioning on both the environment state and the approximate belief. In two toy domains, we illustrate how variBAD performs structured online exploration as a function of task uncertainty. We further evaluate variBAD on MuJoCo tasks widely used in meta-RL and show that it achieves higher online return than existing methods. On the recently proposed Meta-World ML1 benchmark, variBAD achieves state of the art results by a large margin, fully solving two out of the three ML1 tasks for the first time.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#90323D"><a href="">ICML</a></abbr></div>

        <!-- Entry bib key -->
        <div id="zintgraf2021exploration" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploration in approximate hyper-state space for meta reinforcement learning</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://luisazintgraf.com/" rel="external nofollow noopener" target="_blank">Luisa M Zintgraf</a>, <em>Leo Feng</em>, <a href="https://www.conglu.co.uk/" rel="external nofollow noopener" target="_blank">Cong Lu</a>, <a href="https://scholar.google.com/citations?user=rFcdDJEAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Maximilian Igl</a>, <a href="https://hartikainen.github.io/" rel="external nofollow noopener" target="_blank">Kristian Hartikainen</a>, <a href="https://scholar.google.com/citations?user=bHsjbLwAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Katja Hofmann</a>, and <a href="https://scholar.google.com/citations?user=9zeEI-cAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Shimon Whiteson</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Machine Learning</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2010.01062" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://proceedings.mlr.press/v139/zintgraf21a" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/lmzintgraf/hyperx" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>To rapidly learn a new task, it is often essential for agents to explore efficiently - especially when performance matters from the first timestep. One way to learn such behaviour is via meta-learning. Many existing methods however rely on dense rewards for meta-training, and can fail catastrophically if the rewards are sparse. Without a suitable reward signal, the need for exploration during meta-training is exacerbated. To address this, we propose HyperX, which uses novel reward bonuses for meta-training to explore in approximate hyper-state space (where hyper-states represent the environment state and the agent’s task belief). We show empirically that HyperX meta-learns better task-exploration and adapts more successfully to new tasks than existing methods.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>


        </article>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Leo  Feng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: January 17, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
